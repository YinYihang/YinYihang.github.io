<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<meta http-equiv="Content-Type" content="text/html"; charset="utf-8">
<head lang="en">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1.0, maximum-scale=1.0, minimal-ui" />

    <title>Aaron.yee  | (转) Neural Networks, Manifolds, and Topology </title>

    <script>document.cookie='resolution='+Math.max(screen.width,screen.height)+'; path=/';</script>
    <style>
article,aside,details,figcaption,figure,footer,header,hgroup,main,menu,nav,pre,section,summary{display:block}.main-content article.abstract,.main-content h1,.main-content h2,.main-content h3,.main-content h4,.main-content h5,.main-content h6,blockquote{border-bottom:1px solid #272626}@font-face{font-family:'Fira Mono';src:url(/fonts/FiraMono-3.2/FiraMono-Bold.eot),url(/fonts/FiraMono-3.2/FiraMono-Bold.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraMono-3.2/FiraMono-Bold.woff2)format("woff2"),url(/fonts/FiraMono-3.2/FiraMono-Bold.woff)format("woff"),url(/fonts/FiraMono-3.2/FiraMono-Bold.ttf)format("truetype");font-weight:700;font-style:normal}@font-face{font-family:'Fira Mono';src:url(/fonts/FiraMono-3.2/FiraMono-Medium.eot),url(/fonts/FiraMono-3.2/FiraMono-Medium.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraMono-3.2/FiraMono-Medium.woff2)format("woff2"),url(/fonts/FiraMono-3.2/FiraMono-Medium.woff)format("woff"),url(/fonts/FiraMono-3.2/FiraMono-Medium.ttf)format("truetype");font-weight:500;font-style:normal}@font-face{font-family:'Fira Mono';src:url(/fonts/FiraMono-3.2/FiraMono-Regular.eot),url(/fonts/FiraMono-3.2/FiraMono-Regular.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraMono-3.2/FiraMono-Regular.woff2)format("woff2"),url(/fonts/FiraMono-3.2/FiraMono-Regular.woff)format("woff"),url(/fonts/FiraMono-3.2/FiraMono-Regular.ttf)format("truetype");font-weight:400;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-Bold.eot),url(/fonts/FiraSans-4.1/FiraSans-Bold.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-Bold.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-Bold.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-Bold.ttf)format("truetype");font-weight:700;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-BoldItalic.eot),url(/fonts/FiraSans-4.1/FiraSans-BoldItalic.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-BoldItalic.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-BoldItalic.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-BoldItalic.ttf)format("truetype");font-weight:700;font-style:italic}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-ExtraBold.eot),url(/fonts/FiraSans-4.1/FiraSans-ExtraBold.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-ExtraBold.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-ExtraBold.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-ExtraBold.ttf)format("truetype");font-weight:800;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-ExtraBoldItalic.eot),url(/fonts/FiraSans-4.1/FiraSans-ExtraBoldItalic.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-ExtraBoldItalic.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-ExtraBoldItalic.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-ExtraBoldItalic.ttf)format("truetype");font-weight:800;font-style:italic}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-Heavy.eot),url(/fonts/FiraSans-4.1/FiraSans-Heavy.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-Heavy.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-Heavy.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-Heavy.ttf)format("truetype");font-weight:900;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-HeavyItalic.eot),url(/fonts/FiraSans-4.1/FiraSans-HeavyItalic.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-HeavyItalic.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-HeavyItalic.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-HeavyItalic.ttf)format("truetype");font-weight:900;font-style:italic}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-Italic.eot),url(/fonts/FiraSans-4.1/FiraSans-Italic.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-Italic.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-Italic.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-Italic.ttf)format("truetype");font-weight:4.1;font-style:italic}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-Light.eot),url(/fonts/FiraSans-4.1/FiraSans-Light.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-Light.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-Light.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-Light.ttf)format("truetype");font-weight:300;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-LightItalic.eot),url(/fonts/FiraSans-4.1/FiraSans-LightItalic.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-LightItalic.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-LightItalic.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-LightItalic.ttf)format("truetype");font-weight:300;font-style:italic}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-Medium.eot),url(/fonts/FiraSans-4.1/FiraSans-Medium.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-Medium.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-Medium.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-Medium.ttf)format("truetype");font-weight:500;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-MediumItalic.eot),url(/fonts/FiraSans-4.1/FiraSans-MediumItalic.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-MediumItalic.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-MediumItalic.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-MediumItalic.ttf)format("truetype");font-weight:500;font-style:italic}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-Regular.eot),url(/fonts/FiraSans-4.1/FiraSans-Regular.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-Regular.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-Regular.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-Regular.ttf)format("truetype");font-weight:400;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-SemiBold.eot),url(/fonts/FiraSans-4.1/FiraSans-SemiBold.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-SemiBold.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-SemiBold.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-SemiBold.ttf)format("truetype");font-weight:600;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-SemiBoldItalic.eot),url(/fonts/FiraSans-4.1/FiraSans-SemiBoldItalic.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-SemiBoldItalic.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-SemiBoldItalic.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-SemiBoldItalic.ttf)format("truetype");font-weight:600;font-style:italic}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-Thin.eot),url(/fonts/FiraSans-4.1/FiraSans-Thin.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-Thin.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-Thin.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-Thin.ttf)format("truetype");font-weight:100;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-ThinItalic.eot),url(/fonts/FiraSans-4.1/FiraSans-ThinItalic.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-ThinItalic.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-ThinItalic.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-ThinItalic.ttf)format("truetype");font-weight:100;font-style:italic}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-UltraLight.eot),url(/fonts/FiraSans-4.1/FiraSans-UltraLight.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-UltraLight.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-UltraLight.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-UltraLight.ttf)format("truetype");font-weight:200;font-style:normal}@font-face{font-family:'Fira Sans';src:url(/fonts/FiraSans-4.1/FiraSans-UltraLightItalic.eot),url(/fonts/FiraSans-4.1/FiraSans-UltraLightItalic.eot?#iefix)format("embedded-opentype"),url(/fonts/FiraSans-4.1/FiraSans-UltraLightItalic.woff2)format("woff2"),url(/fonts/FiraSans-4.1/FiraSans-UltraLightItalic.woff)format("woff"),url(/fonts/FiraSans-4.1/FiraSans-UltraLightItalic.ttf)format("truetype");font-weight:200;font-style:italic}a,abbr,acronym,address,applet,article,aside,audio,b,big,blockquote,body,canvas,caption,center,cite,code,dd,del,details,dfn,div,dl,dt,em,embed,fieldset,figcaption,figure,footer,form,h1,h2,h3,h4,h5,h6,header,hgroup,html,i,iframe,img,ins,kbd,label,legend,li,mark,menu,nav,object,ol,output,p,pre,q,ruby,s,samp,section,small,span,strike,strong,sub,summary,sup,table,tbody,td,tfoot,th,thead,time,tr,tt,u,ul,var,video{margin:0;padding:0;border:0;font:inherit;font-size:100%;vertical-align:baseline}pre,pre code{font-size:1rem}table{border-collapse:collapse;border-spacing:0}caption,td,th{text-align:left;font-weight:400;vertical-align:middle}blockquote,q{quotes:none}blockquote:after,blockquote:before,q:after,q:before{content:"";content:none}a img{border:none}.main-content section#facts{z-index:0;padding:1em 1em 1.4em;-moz-transition:all .5s ease;-o-transition:all .5s ease;-webkit-transition:all .5s ease;transition:all .5s ease}#sidebar .leaver .trigger,#sidebar .leaver .trigger div{position:absolute;transition:all .3s ease;-webkit-transition:all .3s ease}@media (min-width:64rem){.main-content section#facts{padding:1em 2em 1.4em}}code{padding:2px 4px;border:1px solid #e1e1e8;white-space:nowrap}pre,pre code{white-space:pre}pre{padding:9.5px;margin:0 0 10px;line-height:20px;overflow:scroll;border:1px solid #ccc;border:1px solid rgba(0,0,0,.15)}pre.prettyprint{margin-bottom:20px}pre code{font-family:"Fira Mono","Droid Sans Mono",Monaco,Menlo,Consolas,"Courier New",monospace;padding:0;color:inherit;background-color:transparent;border:0}code,pre{color:#ccc;background-color:#303030}code>span.kw{color:#f0dfaf}code>span.dt{color:#dfdfbf}code>span.dv{color:#dcdccc}code>span.bn{color:#dca3a3}code>span.fl{color:#c0bed1}code>span.ch{color:#dca3a3}code>span.st{color:#cc9393}code>span.co{color:#7f9f7f}code>span.ot{color:#efef8f}code>span.al{color:#ffcfaf}code>span.fu{color:#efef8f}code>span.er{color:#c3bf9f}.main-content .fn{font-weight:500}.main-content article>*>:last-child{padding-bottom:0}.main-content div.more{text-align:right}.main-content article header{padding-top:1em;padding-bottom:0}.main-content article header .date{font-size:.75em;font-weight:300}.main-content article footer .meta-info{padding:.5em 0;border-bottom:1px solid #272626;border-top:1px solid #272626}.main-content #credit,.main-content .background,.main-content h1.section-head,.main-content h1.section-head::before{display:none}@media (min-width:64rem){.main-content #aboutbg #credit a,.main-content #aboutbg #credit a:hover,.main-content #aboutbg #credit a:visited,.main-content #talkbg #credit a,.main-content #talkbg #credit a:hover,.main-content #talkbg #credit a:visited{color:#272626}.main-content #credit a,.main-content #credit a:hover,.main-content #credit a:visited,.main-content h1.section-head{color:#F2F2F2;text-decoration:none}.main-content .background{position:fixed;top:0;right:0;bottom:0;left:45rem;display:block}.main-content #blogbg{background:linear-gradient(to bottom,rgba(39,38,38,0)0,rgba(39,38,38,0)50%,rgba(39,38,38,.25)100%),url(/assets/images/beanbag.jpg)center/cover no-repeat}.main-content #archivebg{background:50%,url(/assets/images/archive.jpg)45%/cover no-repeat}.main-content #contactbg{background:linear-gradient(to bottom,rgba(39,38,38,0)0,rgba(39,38,38,0)50%,rgba(39,38,38,.25)100%),url(/assets/images/mailboxi.jpg)bottom/cover no-repeat}.main-content #tagbg{background:linear-gradient(to bottom,rgba(39,38,38,0)0,rgba(39,38,38,0)50%,rgba(39,38,38,.25)100%),url(/assets/images/indexcardbox.jpg)center/cover no-repeat}.main-content #aboutbg{background:linear-gradient(to bottom,rgba(39,38,38,0)0,rgba(39,38,38,0)50%,rgba(39,38,38,.25)100%),url(/assets/images/SIGINT_Martin_bw_small.jpg)50%/cover no-repeat}.main-content #talkbg{background:linear-gradient(to bottom,rgba(39,38,38,0)0,rgba(39,38,38,0)50%,rgba(39,38,38,.25)100%),url(/assets/images/lecture_hall_bw.jpg)center/cover no-repeat}.main-content #credit{position:absolute;top:-.5em;right:.5em;bottom:auto;left:auto;display:block;width:20rem;font-size:.8em;font-weight:300;text-align:right;-moz-transform:rotate(-90deg);-ms-transform:rotate(-90deg);-webkit-transform:rotate(-90deg);transform:rotate(-90deg);-moz-transform-origin:bottom right;-ms-transform-origin:bottom right;-webkit-transform-origin:bottom right;transform-origin:bottom right;color:#F2F2F2}.main-content h1.section-head{position:fixed;display:block;text-transform:lowercase;font-weight:700;bottom:1.25rem;right:1.5rem;font-size:4rem;margin:0;padding:0;line-height:1;border-bottom:none}.main-content h1.section-head::before{position:absolute;display:block;bottom:.5rem;left:-1.25rem;margin-bottom:3px;content:"";width:1rem;height:1rem;color:#F60A20;background:#F60A20}}@media (min-width:80rem){.main-content h1.section-head{font-size:6rem}.main-content h1.section-head::before{bottom:1rem;margin-bottom:0}}.main-content article>*{padding:1em}@media (min-width:48rem){.main-content footer.meta-info{font-size:1.125rem;padding:.5rem 0;border-bottom:1px solid #272626;border-top:1px solid #272626}}@media (min-width:64rem){.main-content article>*{padding:0 2em 1em}.main-content #article-bg{display:block}}#sidebar footer.details,.main-content.show #more-arrow{display:none}#menu-closer,#menu-opener,.trigger{curser:pointer}#more-arrow{position:fixed;bottom:0;left:20em;width:5em}#more-arrow svg{width:5em;height:5em}.arrow-down{stroke:rgba(242,242,242,.9);fill:none}#lambda{stroke:#F2F2F2;fill:#F2F2F2}#dot{fill:#F60A20;stroke:#F60A20}#sidebar{font-size:.75rem;color:#F2F2F2;background-color:#404040}#sidebar .sidebar-content nav a h1,#sidebar .sidebar-content nav a:visited h1,#sidebar h1{font-size:3em}#sidebar h1{font-weight:700}#sidebar .leaver{position:fixed;top:0;right:0;bottom:auto;left:0;z-index:100;width:100%;height:5em;background-color:#272626}#sidebar .leaver .trigger{top:0;right:auto;bottom:auto;left:0;height:5em;width:5em;overflow:hidden;text-align:center;line-height:2em;-moz-transition:all .3s ease;-o-transition:all .3s ease}#sidebar .leaver .trigger div{width:3em;height:3em;padding:1em;-moz-transition:all .3s ease;-o-transition:all .3s ease;-moz-transform:translate3d(0,-100%,0);-webkit-transform:translate3d(0,-100%,0);transform:translate3d(0,-100%,0)}#sidebar .leaver .trigger div img{width:3em;height:auto}#sidebar .leaver .trigger .menu-close{top:0;background-color:#F60A20}#sidebar .leaver .trigger .menu{top:5em;left:0;background-color:#404040}#sidebar .leaver footer.logo{position:absolute;top:auto;right:0;bottom:0;left:auto;width:5em;height:5em;line-height:5em}#sidebar .sidebar-content nav,h1,h2,h3,h4,h5,h6{line-height:1.2}#sidebar .leaver footer.logo svg{width:100%;height:auto}#sidebar .leaver footer.logo svg .lambda{fill:#F2F2F2}#sidebar .leaver footer.logo svg .dot{fill:#F60A20}#sidebar .leaver footer.logo img.logo{display:block;margin:0 auto;width:100%;height:100%}#sidebar .sidebar-content{position:fixed;top:5em;right:0;bottom:0;left:0;z-index:75;background-color:#404040;-moz-transition:all .3s ease;-o-transition:all .3s ease;-webkit-transition:all .3s ease;transition:all .3s ease;-moz-transform:translate3d(-100%,-100%,0)translate3d(5em,0,0);-ms-transform:translate3d(-100%,-100%,0)translate3d(5em,0,0);-webkit-transform:translate3d(-100%,-100%,0)translate3d(5em,0,0);transform:translate3d(-100%,-100%,0)translate3d(5em,0,0)}#sidebar .sidebar-content section.menu{position:absolute;top:1.25em;right:3.5em;bottom:11em;left:3.5em}#sidebar .sidebar-content nav a,#sidebar .sidebar-content nav a:visited{margin-bottom:.5em;padding:.5em 1.5em;font-weight:700;display:block;color:#F2F2F2;text-decoration:none;border:1px solid transparent;background-color:#404040;opacity:0;-moz-transform:translate3d(0,-1em,0);-webkit-transform:translate3d(0,-1em,0);transform:translate3d(0,-1em,0);-moz-transition:opacity .3s ease,-moz-transform .3s ease,border-color .5s ease;-o-transition:opacity .3s ease,-o-transform .3s ease,border-color .5s ease;-webkit-transition:opacity .3s ease,-webkit-transform .3s ease,border-color .5s ease;transition:opacity .3s ease,transform .3s ease,border-color .5s ease}#sidebar .sidebar-content nav a h2,#sidebar .sidebar-content nav a:visited h2{line-height:1.4;font-size:1.25em;font-weight:300}#sidebar .sidebar-content nav a:nth-child(1){-moz-transition-delay:350ms,350ms,0s;-o-transition-delay:350ms,350ms,0s;-webkit-transition-delay:350ms,350ms,0s;transition-delay:350ms,350ms,0s}#sidebar .sidebar-content nav a:nth-child(2){-moz-transition-delay:400ms,400ms,0s;-o-transition-delay:400ms,400ms,0s;-webkit-transition-delay:400ms,400ms,0s;transition-delay:400ms,400ms,0s}#sidebar .sidebar-content nav a:nth-child(3){-moz-transition-delay:450ms,450ms,0s;-o-transition-delay:450ms,450ms,0s;-webkit-transition-delay:450ms,450ms,0s;transition-delay:450ms,450ms,0s}#sidebar .sidebar-content nav a:nth-child(4){-moz-transition-delay:500ms,500ms,0s;-o-transition-delay:500ms,500ms,0s;-webkit-transition-delay:500ms,500ms,0s;transition-delay:500ms,500ms,0s}#sidebar .sidebar-content nav a:nth-child(5){-moz-transition-delay:550ms,550ms,0s;-o-transition-delay:550ms,550ms,0s;-webkit-transition-delay:550ms,550ms,0s;transition-delay:550ms,550ms,0s}#sidebar .sidebar-content nav a:nth-child(6){-moz-transition-delay:600ms,600ms,0s;-o-transition-delay:600ms,600ms,0s;-webkit-transition-delay:600ms,600ms,0s;transition-delay:600ms,600ms,0s}#sidebar .sidebar-content nav a:hover{border:1px solid #8C8979;z-index:2}#sidebar footer.details{position:absolute;top:auto;right:0;bottom:0;left:0;margin:0 5rem;height:10.5rem;font-size:.75rem;font-weight:300;line-height:1.4;border-top:1px solid #8C8979;opacity:0;-moz-transform:translate3d(0,-1em,0);-webkit-transform:translate3d(0,-1em,0);transform:translate3d(0,-1em,0);-moz-transition:all .3s ease .65s;-o-transition:all .3s ease .65s;-webkit-transition:all .3s ease;-webkit-transition-delay:.65s;transition:all .3s ease .65s}#sidebar.open .leaver .trigger div,#sidebar.open .sidebar-content,#sidebar.open .sidebar-content footer.details{-webkit-transform:translate3d(0,0,0)}#sidebar.open .leaver .trigger div,#sidebar.open .sidebar-content,#sidebar.open .sidebar-content footer.details,#sidebar.open nav a,#sidebar.open nav a:visited{-moz-transform:translate3d(0,0,0);transform:translate3d(0,0,0)}#sidebar footer.details a,#sidebar footer.details a:visited{color:#F2F2F2;text-decoration:underline;font-weight:400}#sidebar footer.details div.vcard .n,blockquote{font-weight:500}#sidebar footer.details a img,#sidebar footer.details a:visited img{display:block;margin:1em 0 0 auto}ol li,ul li{margin-left:2em}#sidebar footer.details div.vcard{width:10rem;margin-top:.5em}#sidebar footer.details div.vcard>div{margin-bottom:.5em}#sidebar footer.details div.licence{position:absolute;top:.5em;right:0;bottom:auto;left:auto;width:12em;text-align:right}#sidebar footer.details div.licence h1{font-size:1em;font-weight:500;margin-bottom:.5em}#sidebar.open nav a,#sidebar.open nav a:visited{opacity:1;-webkit-transform:translate3d(0,0,0)}#sidebar.open .sidebar-content footer.details{font-size:1em;opacity:1}@media (min-width:48rem){#sidebar{font-size:1rem}}@media (min-width:64rem){#sidebar{font-size:1rem}#sidebar .leaver{position:fixed;top:0;right:auto;bottom:0;left:0;width:5em;height:100%}#sidebar .leaver .trigger div{-moz-transform:translate3d(-100%,0,0);-webkit-transform:translate3d(-100%,0,0);transform:translate3d(-100%,0,0)}#sidebar .leaver .trigger .menu{top:0;left:5em}#sidebar .leaver footer.logo{position:absolute;top:auto;right:auto;bottom:0;left:auto}#sidebar .sidebar-content{top:0;left:5em;-moz-transform:translate3d(-100%,-100%,0)translate3d(0,5em,0);-ms-transform:translate3d(-100%,-100%,0)translate3d(0,5em,0);-webkit-transform:translate3d(-100%,-100%,0)translate3d(0,5em,0);transform:translate3d(-100%,-100%,0)translate3d(0,5em,0)}}@media (min-width:48rem)and (min-height:40rem){#sidebar footer.details{display:block;font-size:1rem}}@media (max-height:30rem){#sidebar nav a,#sidebar nav a:visited{margin-bottom:.1875rem;padding:0 1.125rem}#sidebar nav a h1,#sidebar nav a:visited h1{font-size:3em;line-height:1.2}#sidebar nav a h2,#sidebar nav a:visited h2{display:none}}ol,ul{list-style:none;margin-bottom:1.6em}ul li{list-style:disc}ol li{list-style:decimal}ul.unstyled,ul.unstyled li{list-style:none}ul.inline,ul.inline li{display:inline;list-style:none}ul.unstyled li{margin-left:0}blockquote{margin-bottom:1em;border-top:1px solid #272626;border-left:1em solid #272626;border-right:1px solid #272626;padding:.5rem}blockquote small{display:block;font-size:.8em;text-align:right;font-weight:300}h1,h2,h3,h4,h5,h6{font-weight:900}a,a:visited{font-weight:500;color:#F60A20}p{padding-bottom:1em}h1{font-size:3.5em}h1 a,h1 a:visited,h2 a,h2 a:visited,h3 a,h3 a:visited,h4 a,h4 a:visited,h5 a,h5 a:visited,h6 a,h6 a:visited{color:inherit;text-decoration:none;font-weight:900}h2{font-size:2.53287em}h3{font-size:1.96713em}h4{font-size:1.56574em}h5{font-size:1.25439em}h6{font-size:1em}.tt,strong{font-weight:700}em{font-style:italic}.tt{font-family:"Fira Mono"}.problemstatement{margin:.75rem;padding:.375rem;border:1px solid #272626}@media (min-width:48rem){h1{font-size:3.5em}h2{font-size:2.53287em}h3{font-size:1.96713em}h4{font-size:1.56574em}h5{font-size:1.25439em}h6{font-size:1em}}body,html{height:100%}html{font-family:"Fira Sans",Lato,sans-serif;font-weight:400;line-height:1.6;font-size:16px}body{color:#272626;background-color:#F2F2F2}.main-content h1 a,.main-content h1 a:visited,.main-content h2 a,.main-content h2 a:visited,.main-content h3 a,.main-content h3 a:visited,.main-content h4 a,.main-content h4 a:visited,.main-content h5 a,.main-content h5 a:visited,.main-content h6 a,.main-content h6 a:visited{color:inherit}#indieauth{display:none}.leaflet-container{width:100%;height:30em}.animate{-moz-transition:all 1s ease;-o-transition:all 1s ease;-webkit-transition:all 1s ease;transition:all 1s ease}.animate.ng-enter,.animate.ng-leave.ng-leave-active{position:absolute;top:0;left:0;right:0;opacity:0}.animate.ng-enter.ng-enter-active{opacity:1}.main-content{font-size:.875rem;font-weight:400;height:100%;max-width:40rem;margin:3.75rem auto 0;z-index:50}.main-content h1,.main-content h2,.main-content h3,.main-content h4,.main-content h5,.main-content h6{margin-bottom:.75rem}.main-content>section{padding:2em}.main-content section>:last-child{padding-bottom:0;margin-bottom:0}.main-content section{will-change:transform,opacity;padding-bottom:2em}.main-content section p{padding-bottom:1em}.main-content section p:last-child{padding-bottom:0}.main-content img{display:block;max-width:90%;height:auto;margin:0 auto 1.6em}.main-content a,.main-content a:visited{color:#F60A20}.main-content table.meta{margin-bottom:1.6em}.main-content table.meta td.heading{font-weight:500;padding-right:.5em}.main-content table.meta td{vertical-align:top}@media (min-width:48rem){.main-content{margin:5em auto 0;font-size:1rem;width:40em}.main-content h1,.main-content h2,.main-content h3,.main-content h4,.main-content h5,.main-content h6{margin-bottom:1rem;border-bottom:1px solid #272626}}@media (min-width:64rem){.main-content{margin:0 0 0 5em}.main-content>section{padding:1em 2em}}#post-archive section.year,#tags section.year,#talk-archive section.year{border-top:thin solid #272626;padding-top:.5em}#post-archive section.year:first-child,#tags section.year:first-child,#talk-archive section.year:first-child{border-top:none;padding-top:0}#post-archive section.year h2.year,#tags section.year h2.year,#talk-archive section.year h2.year{float:left;width:6rem;border-bottom:none;overflow:hidden}@media (min-width:48rem){#post-archive section.year h2.year,#tags section.year h2.year,#talk-archive section.year h2.year{width:8rem}}#post-archive section.year section.month,#tags section.year section.month,#talk-archive section.year section.month{margin-left:8em}#post-archive span.day,#tags span.day,#talk-archive span.day{display:block;width:4em;float:left;font-weight:900}#post-archive span.title,#tags span.title,#talk-archive span.title{display:block;margin-left:4em}#post-archive span.date,#tags span.date,#talk-archive span.date{float:left;display:block;width:7em;font-weight:900}.archive{padding:1em 2em;font-size:2em;text-align:center}.elastic-container{position:relative;padding-bottom:56.25%!important;padding-top:30px!important;height:0;overflow:hidden;margin:auto 2em}.elastic-container embed,.elastic-container iframe,.elastic-container object{position:absolute;top:0;left:0;width:100%;height:100%}@media (min-width:64rem){.half{float:left;width:50%}.activities::after,.vcard::after{content:"\0020";display:block;height:0;clear:both;overflow:hidden;visibility:hidden}}
</style>
</head>

<body>
<div id="indieauth">
    <ul>
        <li><a rel="me" href="mailto:yinyhmail@gmail.com">yinyhmail@gmail.com</a></li>
        <li><a rel="me" href="https://github.com/AaronYee">Aaron</a> on Github</li>
        <li><a rel="me" href="http://weibo.com/u/3210788245">@xinitrc</a> on Sina</li>
        <li><a rel="me" href="https://plus.google.com/+yinyhmai@gmail.com/">Aaron</a> on Google+</li>
    </ul>
</div>
<div id="sidebar">
    <div class="leaver">
        <div class="trigger">
            <a href="" id="menu-closer" title="Close Menu">
                <div class="menu-close">
                    <img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KCgo8IS0tIFRoZSBpY29uIGN
hbiBiZSB1c2VkIGZyZWVseSBpbiBib3RoIHBlcnNvbmFsIGFuZCBjb21tZXJjaWFsIHByb2plY3
RzIHdpdGggbm8gYXR0cmlidXRpb24gcmVxdWlyZWQsIGJ1dCBhbHdheXMgYXBwcmVjaWF0ZWQuI
ApZb3UgbWF5IE5PVCBzdWItbGljZW5zZSwgcmVzZWxsLCByZW50LCByZWRpc3RyaWJ1dGUgb3Ig
b3RoZXJ3aXNlIHRyYW5zZmVyIHRoZSBpY29uIHdpdGhvdXQgZXhwcmVzcyB3cml0dGVuIHBlcm1
pc3Npb24gZnJvbSBpY29ubW9uc3RyLmNvbSAtLT4KCgo8IURPQ1RZUEUgc3ZnIFBVQkxJQyAiLS
8vVzNDLy9EVEQgU1ZHIDEuMS8vRU4iICJodHRwOi8vd3d3LnczLm9yZy9HcmFwaGljcy9TVkcvM
S4xL0RURC9zdmcxMS5kdGQiPgoKPHN2ZyB2ZXJzaW9uPSIxLjEiIHhtbG5zPSJodHRwOi8vd3d3
LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzMub3JnLzE5OTkveGx
pbmsiIHg9IjBweCIgeT0iMHB4IgoKCSB3aWR0aD0iNTEycHgiIGhlaWdodD0iNTEycHgiIHZpZX
dCb3g9IjAgMCA1MTIgNTEyIiBlbmFibGUtYmFja2dyb3VuZD0ibmV3IDAgMCA1MTIgNTEyIiB4b
Ww6c3BhY2U9InByZXNlcnZlIj4KCjxwb2x5Z29uIGlkPSJ4LW1hcmstaWNvbiIgZmlsbD0iI0Yy
RjJGMiIgcG9pbnRzPSI0MzguMzkzLDM3NC41OTUgMzE5Ljc1NywyNTUuOTc3IDQzOC4zNzgsMTM
3LjM0OCAzNzQuNTk1LDczLjYwNyAyNTUuOTk1LDE5Mi4yMjUgMTM3LjM3NSw3My42MjIKCgk3My
42MDcsMTM3LjM1MiAxOTIuMjQ2LDI1NS45ODMgNzMuNjIyLDM3NC42MjUgMTM3LjM1Miw0MzguM
zkzIDI1Ni4wMDIsMzE5LjczNCAzNzQuNjUyLDQzOC4zNzggIi8+Cgo8L3N2Zz4=" alt="Menu Close"/>
                </div>
            </a>
            <a href="" id="menu-opener" title="Menu">
                <div class="menu">
                    <img src="data:image/svg+xml;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0idXRmLTgiPz4KCjwhLS0gTGljZW5zZSBBZ3J
lZW1lbnQgYXQgaHR0cDovL2ljb25tb25zdHIuY29tL2xpY2Vuc2UvIC0tPgoKPCFET0NUWVBFIH
N2ZyBQVUJMSUMgIi0vL1czQy8vRFREIFNWRyAxLjEvL0VOIiAiaHR0cDovL3d3dy53My5vcmcvR
3JhcGhpY3MvU1ZHLzEuMS9EVEQvc3ZnMTEuZHRkIj4KPHN2ZyB2ZXJzaW9uPSIxLjEiIHhtbG5z
PSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgeG1sbnM6eGxpbms9Imh0dHA6Ly93d3cudzM
ub3JnLzE5OTkveGxpbmsiIHg9IjBweCIgeT0iMHB4IgoJIHdpZHRoPSI1MTJweCIgaGVpZ2h0PS
I1MTJweCIgdmlld0JveD0iMCAwIDUxMiA1MTIiIGVuYWJsZS1iYWNrZ3JvdW5kPSJuZXcgMCAwI
DUxMiA1MTIiIHhtbDpzcGFjZT0icHJlc2VydmUiPgo8cGF0aCBmaWxsPSIjZjJmMmYyIiBpZD0i
bWVudS1pY29uIiBkPSJNNDYyLDE2My41SDUwdi02NWg0MTJWMTYzLjV6IE00NjIsMjIzLjVINTB
2NjVoNDEyVjIyMy41eiBNNDYyLDM0OC41SDUwdjY1aDQxMlYzNDguNXoiLz4KPC9zdmc+" alt="Menu"/>
                </div>
            </a>
        </div>
        <footer class="logo">
<?xml version="1.0" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg viewbox="0 0 32 32" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:1.41421;">
                <path d="M15.9754,20.8345L8.76062,28.0492L3.95078,23.2394L11.1655,16.0246L3.95078,8.80984L8.76062,4L28,23.2394L23.1902,28.0492L15.9754,20.8345Z" class="lambda"/>
                <path d="M18.9816,8.50922L23.4908,4L28,8.50922L23.4908,13.0184L18.9816,8.50922Z" class="dot"/>
</svg>
        </footer>
    </div>
    <div class="sidebar-content">
        <section class="menu">
            <nav>
                <a href="/">
                    <h1>Blog</h1>
                    <h2>Recordings of knowledge</h2>
                </a>
                <a href="/talks.html">
                    <h1>Talks</h1>
                    <h2>Recordings of life</h2>
                </a>
                <a href="/about.html">
                    <h1>About me</h1>
                    <h2>Details about me</h2>
                </a>
                <a href="/contact.html">
                    <h1>Contact</h1>
                    <h2>Contact and legal information</h2>
                </a>
            </nav>
        </section>
        <footer class="details">

            <div class="vcard">
                <div class="n"><span class="given-name">Aaron</span> <span class="family-name">Yee</span></div>

                <div class="adr">
                    <div class="street-address">No.132, East Outer Ring Road, Guangzhou Higher Education Mega Center, Guangzhou.</div>
                    <div class="country-name">China</div>
                </div>
            </div>
            <div class="licence">
                <h1>Licence</h1>
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>
                <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
                    <img alt="Creative Commons License" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAFgAAAAfCAYAAABjyArgAAAACXBIWXMAAAsTAAALEwEAmpwYAAA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" class="cc-button">
                </a>
            </div>
        </footer>
    </div>
</div>

<div>
        <div class="main-content show">
        <div id="blogbg" class="background">
            <h1 class="section-head">blog</h1>
            <div id="credit">
                <a href="https://www.flickr.com/photos/thomasleuthard">Background image by Thomas Leuthard</a>
            </div>
        </div>
        <article class="full-article">
            <header>
                <span class="date"><time pubdate>2015-09-17</time></span>
	</header>
	<div class="article-body">
	  <h1>(转) Neural Networks, Manifolds, and Topology</h1>
	  <p>An exciting visualization of deep neural networks.</p>
<!--more-->
<p>Recently, there’s been a great deal of excitement and interest in deep neural networks because they’ve achieved breakthrough results in areas such as computer vision.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
<p>However, there remain a number of concerns about them. One is that it can be quite challenging to understand <em>what</em> a neural network is really doing. If one trains it well, it achieves high quality results, but it is challenging to understand how it is doing so. If the network fails, it is hard to understand what went wrong.</p>
<p>While it is challenging to understand the behavior of deep neural networks in general, it turns out to be much easier to explore low-dimensional deep neural networks – networks that only have a few neurons in each layer. In fact, we can create visualizations to completely understand the behavior and training of such networks. This perspective will allow us to gain deeper intuition about the behavior of neural networks observe a connection linking neural networks to an area of mathematics called topology.</p>
<p>A number of interesting things follow from this, including fundamental lower-bounds on the complexity of a neural network capable of classifying certain datasets.</p>
<section id="a-simple-example" class="level2">
<h2>A Simple Example</h2>
<p>Let’s begin with a very simple dataset, two curves on a plane. The network will learn to classify points as belonging to one or the other.</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/simple2_data.png" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>The obvious way to visualize the behavior of a neural network – or any machine learning algorithm, for that matter –’s behavior is to simply look at how it classifies every possible data point.</p>
<p>We’ll start with the simplest possible class of neural network, one with only an input layer and an output layer. Such a network simply tries to separate the two classes of data by dividing them with a line.</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/simple2_linear.png" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>That sort of network isn’t very interesting. Modern neural networks generally have multiple layers between their input and output, called “hidden” layers. At the very least, they have one.</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/example_network.svg" alt="" style="">
<div class="caption">
Diagram of a simple network from Wikipedia
</div>
</div>
<div class="spaceafterimg">
</div>
<p>As before, we can visualize the behavior of this network by looking at what it does to different points in its domain. It separates the data with a more complicated curve than a line.</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/simple2_0.png" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>With each layer, the network transforms the data, creating a new <em>representation</em>.<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> We can look at the data in each of these representations and how the network classifies them. When we get to the final representation, the network will just draw a line through the data (or, in higher dimensions, a hyper-plane).</p>
<p>In the previous visualization, we looked at the data in its “raw” representation. You can think of that as us look at the input layer. Now we will look at it after it is transformed by the first layer. You can think of this as us looking at the hidden layer.</p>
<p>Each dimension corresponds to the firing of a neuron in the layer.</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/simple2_1.png" alt="" style="">
<div class="caption">
The hidden layer learns a representation so that the data is linearly seperable
</div>
</div>
<div class="spaceafterimg">
</div>
</section>
<section id="continuous-visualization-of-layers" class="level2">
<h2>Continuous Visualization of Layers</h2>
<p>In the approach outlined in the previous section, we learn to understand networks by looking at the representation corresponding to each layer. This gives us a discrete list of representations.</p>
<p>The tricky part is in understanding how we go from one to another. Thankfully, neural network layers have nice properties that make this very easy.</p>
<p>There are a variety of different kinds of layers used in neural networks. We will talk about tanh layers for a concrete example. A tanh layer <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>tanh</mi><mo stretchy="false" form="prefix">(</mo><mi>A</mi><mi>x</mi><mo>+</mo><mi>b</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">\tanh(Ax+b)</annotation></semantics></math> consists of:</p>
<ol type="1">
<li>A linear transformation by the matrix <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math></li>
<li>A translation by the vector <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>b</mi><annotation encoding="application/x-tex">b</annotation></semantics></math></li>
<li>Point-wise application of tanh.</li>
</ol>
<p>We can visualize this as a continuous transformation, as follows:</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/1layer.gif" alt="Gradually applying a neural network layer" style="">
</div>
<div class="spaceafterimg">
</div>
<p>The story is much the same for other standard layers, that consist of an affine transformation followed by pointwise application of a monotone activation function.</p>
<p>We can apply this technique to understand more complicated networks. For example, the following network classifies two spirals that are slightly entangled, using many layers.</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/spiral.1-2.2-2-2-2-2-2.gif" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>And the following network fails to classify two spirals that are more entangled, using many layers.</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/spiral.2.2-2-2-2-2-2-2.gif" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>It is worth explicitly noting here that these tasks are only somewhat challenging because we are using low-dimensional neural networks. If we were using wider networks, all this would be quite easy.</p>
</section>
<section id="topology-of-tanh-layers" class="level2">
<h2>Topology of tanh Layers</h2>
<p>Each layer stretches and squishes space, but it never cuts, breaks, or folds it. Intuitively, we can see that it preserves topological properties. For example, a set will be connected afterwards if it was before (and vice versa).</p>
<p>Transformation like this, which don’t affect topology, are called homeomorphisms. Formally, they are bijections that are continuous functions both ways.</p>
<p><strong>Theorem</strong>: Layers with <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> inputs and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>N</mi><annotation encoding="application/x-tex">N</annotation></semantics></math> outputs are homeomorphisms, if <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> is non-singular. (Though one needs to be careful about domain and range.)</p>
<p><strong>Proof</strong>: Let’s consider this step by step:</p>
<ol type="1">
<li>Let’s assume <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> has a non-zero determinant. Then it is a bijective linear function with a linear inverse. Linear functions are continuous. So, multiplying by <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> is a homeomorphism.</li>
<li>Translations are homeomorphisms</li>
<li>tanh (and sigmoid and softplus but not ReLU) are continuous functions with continuous inverses. They are bijections if we are careful about the domain and range we consider. Applying them pointwise is a homemorphism</li>
</ol>
<p>Thus, if W has a non-zero determinant, our layer is a homeomorphism. ∎</p>
<p>This result continues to hold if we compose arbitrarily many of these layers together.</p>
</section>
<section id="topology-and-classification" class="level2">
<h2>Topology and Classification</h2>
<div class="floatrightimgcontainer">
<img src="/assets/images/dl1/topology_base.png" alt="" style="">
<div class="caption">
A is red, B is blue
</div>
</div>
<div class="spaceafterimg">
</div>
<p>Consider a two dimensional dataset with two classes <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>,</mo><mi>B</mi><mo>⊂</mo><msup><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">A, B \subset \mathbb{R}^2</annotation></semantics></math>:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mi>d</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mn>0</mn><mo stretchy="false" form="postfix">)</mo><mo>&lt;</mo><mn>1</mn><mo>/</mo><mn>3</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">A = \{x | d(x,0) &lt; 1/3\}</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mo stretchy="false" form="prefix">{</mo><mi>x</mi><mo stretchy="false" form="prefix">|</mo><mn>2</mn><mo>/</mo><mn>3</mn><mo>&lt;</mo><mi>d</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo>,</mo><mn>0</mn><mo stretchy="false" form="postfix">)</mo><mo>&lt;</mo><mn>1</mn><mo stretchy="false" form="postfix">}</mo></mrow><annotation encoding="application/x-tex">B = \{x | 2/3 &lt; d(x,0) &lt; 1\}</annotation></semantics></math></p>
<p><strong>Claim</strong>: It is impossible for a neural network to classify this dataset without having a layer that has 3 or more hidden units, regardless of depth.</p>
<p>As we discussed previously, classification with a sigmoid unit or a softmax layer would be equivalent to trying to find a hyperplane (or in this case a line) that separates <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>.</p>
<p>Unfortunately, with only two hidden units, a network is topologically doomed to failure on this dataset. We can watch it struggle and try to learn a way to do this:</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/topology_2D-2D_train.gif" alt="" style="">
<div class="caption">
For this network, hard work isn’t enough.
</div>
</div>
<div class="spaceafterimg">
</div>
<p>(It’s actually able to achieve ~80% classification accuracy.)</p>
<p>This example only had one hidden layer, but it would fail regardless.</p>
<p><strong>Proof</strong>: Either each layer is a homeomorphism, or the layer’s weight matrix has determinant 0. If it is a homemorphism, A is still surrounded by B, and a line can’t separate them. But suppose it has a determinant of 0: then the dataset gets collapsed on some axis. Since we’re dealing with something homeomorphic to the original dataset, A is surrounded by B, and collapsing on any axis means we will have some points of A and B mix and become impossible to distinguish between. ∎</p>
<p>If we add a third hidden unit, the problem becomes trivial. The neural network learns the following representation:</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/topology_3d.png" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>With this representation, we can separate the datasets with a hyperplane.</p>
<p>To get a better sense of what’s going on, let’s consider an even simpler dataset that’s 1-dimensional:</p>
<div class="floatrightimgcontainer">
<img src="/assets/images/dl1/topology_1d.png" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mo stretchy="false" form="prefix">[</mo><mo>−</mo><mfrac><mn>1</mn><mn>3</mn></mfrac><mo>,</mo><mfrac><mn>1</mn><mn>3</mn></mfrac><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">A = [-\frac{1}{3}, \frac{1}{3}]</annotation></semantics></math></p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mo stretchy="false" form="prefix">[</mo><mo>−</mo><mn>1</mn><mo>,</mo><mo>−</mo><mfrac><mn>2</mn><mn>3</mn></mfrac><mo stretchy="false" form="postfix">]</mo><mo>∪</mo><mo stretchy="false" form="prefix">[</mo><mfrac><mn>2</mn><mn>3</mn></mfrac><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">]</mo></mrow><annotation encoding="application/x-tex">B = [-1, -\frac{2}{3}] \cup [\frac{2}{3}, 1]</annotation></semantics></math></p>
<p>Without using a layer of two or more hidden units, you can’t classify this dataset. But if you use one with two units, we learn to represent the data as a nice curve that allows us to separate the data:</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/topology_1D-2D_train.gif" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>What’s happening? One hidden unit learns to fire when <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>&gt;</mo><mo>−</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">x &gt; -\frac{1}{2}</annotation></semantics></math> and one learns to fire when <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>&gt;</mo><mfrac><mn>1</mn><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">x &gt; \frac{1}{2}</annotation></semantics></math>. When the first one fires, but not the second, we know that we are in A.</p>
</section>
<section id="the-manifold-hypothesis" class="level2">
<h2>The Manifold Hypothesis</h2>
<p>Is this relevant to real world data sets, like image data? If you take the manifold hypothesis really seriously, I think it bares consideration.</p>
<p>The manifold hypothesis is that natural data forms lower-dimensional manifolds in its embedding space. There are both theoretical<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> and experimental<a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> reasons to believe this to be true. If you believe this, then the task of a classification algorithm is fundamentally to separate a bunch of tangled manifolds.</p>
<p>In the previous examples, one class completely surrounded another. However, it doesn’t seem very likely that the dog image manifold is completely surrounded by the cat image manifold. But there are other, more plausible topological situations that could still pose an issue, as we will see in the next section.</p>
</section>
<section id="links-and-homotopy" class="level2">
<h2>Links And Homotopy</h2>
<p>Another interesting dataset to consider is two linked tori, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>.</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/link.png" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>Much like the previous datasets we considered, this dataset can’t be separated without using <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math> dimensions, namely a <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>4</mn><annotation encoding="application/x-tex">4</annotation></semantics></math>th dimension.</p>
<p>Links are studied in knot theory, an area of topology. Sometimes when you see a link, it isn’t immediately obvious whether it’s an unlink (a bunch of things that are tangled together, but can be separated by continuous deformation) or not.</p>
<div class="bigcenterimgcontainer">
<img src="/assets/images/dl1/unlink-2spiral.png" alt="" style="">
<div class="caption">
A relatively simple unlink.
</div>
</div>
<div class="spaceafterimg">
</div>
<p>If a neural network using layers with only 3 units can classify it, then it is an unlink. (Question: Can all unlinks be classified by a network with only 3 units, theoretically?)</p>
<p>From this knot perspective, our continuous visualization of the representations produced by a neural network isn’t just a nice animation, it’s a procedure for untangling links. In topology, we would call it an <em>ambient isotopy</em> between the original link and the separated ones.</p>
<p>Formally, an ambient isotopy is between manifolds <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math> is a continuous function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo>:</mo><mo stretchy="false" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">]</mo><mo>×</mo><mi>X</mi><mo accent="false">→</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">F: [0,1] \times X \to Y</annotation></semantics></math> such that each <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>F</mi><mi>t</mi></msub><annotation encoding="application/x-tex">F_t</annotation></semantics></math> is a homeomorphism from <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>X</mi><annotation encoding="application/x-tex">X</annotation></semantics></math> to its range, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>F</mi><mn>0</mn></msub><annotation encoding="application/x-tex">F_0</annotation></semantics></math> is the identity function, and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>F</mi><mn>1</mn></msub><annotation encoding="application/x-tex">F_1</annotation></semantics></math> maps <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>. That is, <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>F</mi><mi>t</mi></msub><annotation encoding="application/x-tex">F_t</annotation></semantics></math> continuously transitions from mapping <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> to itself to mapping <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>A</mi><annotation encoding="application/x-tex">A</annotation></semantics></math> to <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>B</mi><annotation encoding="application/x-tex">B</annotation></semantics></math>.</p>
<p><strong>Theorem</strong>: There is an ambient isotopy between the input and a network layer’s representation if: a) W isn’t singular, b) you are willing to permute the neurons in the hidden layer, and c) there is more than 1 hidden unit.</p>
<p><strong>Proof</strong>: Again, we consider each stage of the network individually:</p>
<ol type="1">
<li>The linear transformation is, in fact, the hardest part. In order for this to be possible, we need <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> to have a positive determinant. Our premise is that it isn’t zero, and we can flip the sign if it is negative by switching two of the hidden neurons, so we can guarantee the determinant is positive. The space of positive determinant matrices is path-connected, so there exists <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo>:</mo><mo stretchy="false" form="prefix">[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy="false" form="postfix">]</mo><mo accent="false">→</mo><mi>G</mi><msub><mi>L</mi><mi>n</mi></msub><mo stretchy="false" form="prefix">(</mo><mstyle mathvariant="double-struck"><mi>ℝ</mi></mstyle><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">p: [0,1] \to GL_n(\mathbb{R})</annotation></semantics></math> such that <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mn>0</mn><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>I</mi><mi>d</mi></mrow><annotation encoding="application/x-tex">p(0) = Id</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mi>W</mi></mrow><annotation encoding="application/x-tex">p(1) = W</annotation></semantics></math>. We can continually transition from the identity function to the <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>W</mi><annotation encoding="application/x-tex">W</annotation></semantics></math> transformation with the function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo accent="false">→</mo><mi>p</mi><mo stretchy="false" form="prefix">(</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">x \to p(t)x</annotation></semantics></math></li>
<li>We can continually transition from the identity function to the b translation with the function <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo accent="false">→</mo><mi>x</mi><mo>+</mo><mi>t</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">x \to x + tb</annotation></semantics></math></li>
<li>We can continually transition from the identity function to the pointwise use of σ with the function: <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo accent="false">→</mo><mo stretchy="false" form="prefix">(</mo><mn>1</mn><mo>−</mo><mi>t</mi><mo stretchy="false" form="postfix">)</mo><mi>x</mi><mo>+</mo><mi>t</mi><mi>σ</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">x \to (1-t)x + tσ(x)</annotation></semantics></math>. ∎</li>
</ol>
<p>I imagine there is probably interest in programs automatically discovering such ambient isotopies and automatically proving the equivalence of certain links, or that certain links are separable. It would be interesting to know if neural networks can beat whatever the state of the art is there.</p>
<p><em>(Apparently determining if knots are trivial is NP. This doesn’t bode well for neural networks.)</em></p>
<p>The sort of links we’ve talked about so far don’t seem likely to turn up in real world data, but there are higher dimensional generalizations. It seems plausible such things could exist in real world data.</p>
<p>Links and knots are <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mn>1</mn><annotation encoding="application/x-tex">1</annotation></semantics></math>-dimensional manifolds, but you need 4 dimensions to be able to untangle all of them. Similarly, one can need yet higher dimensional space to be able to unknot <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>-dimensional manifolds. All <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>n</mi><annotation encoding="application/x-tex">n</annotation></semantics></math>-dimensional manifolds can be untangled in <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>n</mi><mo>+</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">2n+2</annotation></semantics></math> dimensions.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
<p><em>(I know very little about knot theory and really need to learn more about what’s known regarding dimensionality and links. If we know a manifold can be embedded in n-dimensional space, instead of the dimensionality of the manifold, what limit do we have?)</em></p>
</section>
<section id="the-easy-way-out" class="level2">
<h2>The Easy Way Out</h2>
<p>The natural thing for a neural net to do, the very easy route, is to try and pull the manifolds apart naively and stretch the parts that are tangled as thin as possible. While this won’t be anywhere close to a genuine solution, it can achieve relatively low classification accuracy and be a tempting local minimum.</p>
<div class="bigcenterimgcontainer">
<img src="/assets/images/dl1/tangle.png" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>It would present itself as very high derivatives on the regions it is trying to stretch, and sharp near-discontinuities. We know these things happen.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> Contractive penalties, penalizing the derivatives of the layers at data points, are the natural way to fight this.<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a></p>
<p>Since these sort of local minima are absolutely useless from the perspective of trying to solve topological problems, topological problems may provide a nice motivation to explore fighting these issues.</p>
<p>On the other hand, if we only care about achieving good classification results, it seems like we might not care. If a tiny bit of the data manifold is snagged on another manifold, is that a problem for us? It seems like we should be able to get arbitrarily good classification results despite this issue.</p>
<p><em>(My intuition is that trying to cheat the problem like this is a bad idea: it’s hard to imagine that it won’t be a dead end.)</em></p>
</section>
<section id="better-layers-for-manipulating-manifolds" class="level2">
<h2>Better Layers for Manipulating Manifolds?</h2>
<p>The more I think about standard neural network layers – that is, with an affine transformation followed by a point-wise activation function – the more disenchanted I feel. It’s hard to imagine that these are really very good for manipulating manifolds.</p>
<p>Perhaps it might make sense to have a very different kind of layer that we use in composition with more traditional ones?</p>
<p>The thing that feels natural to me is to learn a vector field with the direction you want to shift the manifold:</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/grid_vec.png" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>And then deform space based on it:</p>
<div class="centerimgcontainer">
<img src="/assets/images/dl1/grid_bubble.png" alt="" style="">
</div>
<div class="spaceafterimg">
</div>
<p>One could learn the vector field at fixed points (just take some fixed points from the training set to use as anchors) and interpolate in some manner. The vector field above is of the form:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>F</mi><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>=</mo><mfrac><mrow><msub><mi>v</mi><mn>0</mn></msub><msub><mi>f</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msub><mi>v</mi><mn>1</mn></msub><msub><mi>f</mi><mn>1</mn></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><mrow><mn>1</mn><mo>+</mo><msub><mi>f</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo><mo>+</mo><msub><mi>f</mi><mn>1</mn></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">F(x) = \frac{v_0f_0(x) + v_1f_1(x)}{1+f_0(x)+f_1(x)}</annotation></semantics></math></p>
<p>Where <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mn>0</mn></msub><annotation encoding="application/x-tex">v_0</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><msub><mi>v</mi><mn>1</mn></msub><annotation encoding="application/x-tex">v_1</annotation></semantics></math> are vectors and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">f_0(x)</annotation></semantics></math> and <math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>f</mi><mn>1</mn></msub><mo stretchy="false" form="prefix">(</mo><mi>x</mi><mo stretchy="false" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">f_1(x)</annotation></semantics></math> are n-dimensional gaussians. This is inspired a bit by RBFs.</p>
</section>
<section id="k-nearest-neighbor-layers" class="level2">
<h2>K-Nearest Neighbor Layers</h2>
<p>I’ve also begun to think that linear separability may be a huge, and possibly unreasonable amount to demand of a neural network. In some ways, it feels like the natural feeling thing to do would be to use <a href="knn">k-nearest neighbors</a>. However, one clearly needs a good representation before k-NN can work well.</p>
<p>As a first experiment, I trained some ~1% test error MNIST networks (two layer conv nets, no dropout). I then dropped the final softmax layer and used the k-NN algorithm. I was able to consistently achieve a reduction in test error of 0.1-0.2%.</p>
<p>Still, this doesn’t quite feel like the right thing. The network is still trying to do linear classification, but since we use k-NN at test time, it’s able to recover a bit from mistakes it made.</p>
<p>k-NN is differentiable with respect to the representation it’s acting on, because of the 1/distance weighting. As such, we can train a network directly for k-NN classification. This can be thought of as a kind of “nearest neighbor” layer that acts as an alternative to softmax.</p>
<p>Clearly, we don’t want to feedforward our entire training set for each mini-batch. I think a nice approach is to classify each element of the mini-batch based on the classes of other elements of the mini-batch, giving each one a weight of 1/(distance from classification target).<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<p>Sadly, this only gets down to 5-4% test error. Though I’ve put very little effort into playing with hyper-parameters. Using simpler networks gets worse results.</p>
<p>Still, I really aesthetically like this approach, because it seems like what we’re “asking” the network to do is much more reasonable. We want points of the same manifold to be closer than points of others. This should correspond to inflating the space between manifolds for different categories and contracting the individual manifolds. It feels kind of like simplification.</p>
</section>
<section id="conclusion" class="level2">
<h2>Conclusion</h2>
<p>Topological properties of data, such as links, may make it impossible to linearly separate classes using low-dimensional networks, regardless of depth. Even in cases where it is technically possible, such as spirals, it can be very challenging to do so.</p>
<p>To accurately classify data with neural networks, wide layers are sometimes necessary. Further, traditional neural network layers do not seem to be very good at representing important manipulations of manifolds. New layers, specifically motivated by the manifold perspective of machine learning, may be useful supplements.</p>
<p><em>(This is a developing research project. It’s posted as an experiment in doing research openly. I would be delighted to have your feedback on these ideas: you can comment inline or at the end. For typos, technical errors, or clarifications you would like to see added, you are encouraged to make a pull request <a href="https://github.com/colah/NN-Topology-Post">on github</a>.)</em></p>
</section>
<section id="acknowledgments" class="level2">
<h2>Acknowledgments</h2>
<p>Thank you to Yoshua Bengio, Michael Nielsen, Dario Amodei, Eliana Lorch, Jacob Steinhardt, and Tamsyn Waterhouse for their comments and encouragement.</p>
<div class="references">

</div>
</section>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p>This seems to have really kicked off with <a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizhevsky <em>et al.</em>, (2012)</a>, who put together a lot of different pieces to achieve outstanding results. Since then there’s been a lot of other exciting work.<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>These representations, hopefully, make the data “nicer” for the network to classify. There has been a lot of work exploring representations recently. Perhaps the most fascinating has been in Natural Language Processing: the representations we learn of words, called word embeddings, have interesting properties. See <a href="http://research.microsoft.com/pubs/189726/rvecs.pdf">Mikolov <em>et al.</em> (2013)</a>, <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/turian-wordrepresentations-acl10.pdf">Turian <em>et al.</em> (2010)</a>, and, <a href="http://www.socher.org/">Richard Socher’s work</a>. To give you a quick flavor, there is a <a href="http://metaoptimize.s3.amazonaws.com/cw-embeddings-ACL2010/embeddings-mostcommon.EMBEDDING_SIZE=50.png">very nice visualization</a> associated with the Turian paper.<a href="#fnref2">↩</a></p></li>
<li id="fn3"><p>A lot of the natural transformations you might want to perform on an image, like translating or scaling an object in it, or changing the lighting, would form continuous curves in image space if you performed them continuously.<a href="#fnref3">↩</a></p></li>
<li id="fn4"><p><a href="http://comptop.stanford.edu/u/preprints/mumford.pdf">Carlsson <em>et al.</em></a> found that local patches of images form a klein bottle.<a href="#fnref4">↩</a></p></li>
<li id="fn5"><p>This result is mentioned in <a href="http://en.wikipedia.org/wiki/Whitney_embedding_theorem#Isotopy_versions">Wikipedia’s subsection on Isotopy versions</a>.<a href="#fnref5">↩</a></p></li>
<li id="fn6"><p>See <a href="http://cs.nyu.edu/~zaremba/docs/understanding.pdf">Szegedy <em>et al.</em></a>, where they are able to construct take data samples and find slight modifications that cause some of the best image classification neural networks to misclasify the data. It’s quite troubling.<a href="#fnref6">↩</a></p></li>
<li id="fn7"><p>Contractive penalties were introduced in contractive autoencoders. See <a href="http://www.iro.umontreal.ca/~lisa/pointeurs/ICML2011_explicit_invariance.pdf">Rifai <em>et al.</em> (2011)</a>.<a href="#fnref7">↩</a></p></li>
<li id="fn8"><p>I used a slightly less elegant, but roughly equivalent algorithm because it was more practical to implement in Theano: feedforward two different batches at the same time, and classify them based on each other.<a href="#fnref8">↩</a></p></li>
</ol>
</section>
	  </div>
            <footer>
                <div class="meta-info">
                    <table class="meta">
                        <tr>
                            <td class="heading">
                                Tags:
                            </td>
                            <td>
                        <span>
                            <a href="/tags/neural-networks.html">neural networks</a>, <a href="/tags/deep-learning.html">deep learning</a>
                        </span>
                            </td>
                        </tr>
                        <tr>
                            <td class="heading">
                                Licence:</td>
                            <td><a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons
                                Attribution-ShareAlike 4.0 Unported License</a></td>
                        </tr>
                    </table>
                    <div class="flattr">
                        <a class="FlattrButton" href="https://xinitrc.de/blog/2015/09/17/deep-learning-1.html" title="(转) Neural Networks, Manifolds, and Topology" lang="en"
                           data-flattr-uid="xinitrc"
                           data-flattr-tags="blog"
                           data-flattr-category="text"></a>
                    </div>
                </div>
                
                    <div disqus="url"></div>
                <div id="disqus_thread"></div>
                <script type="text/javascript">
                    var disqus_shortname = 'aaronyeegithubio'; // required: replace example with your forum shortname
                    (function () {
                        var dsq = document.createElement('script');
                        dsq.type = 'text/javascript';
                        dsq.async = true;
                        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                    })();
                </script>
                <noscript>Please enable JavaScript to view the <a href="//disqus.com/?ref_noscript">comments powered by
                    Disqus.</a></noscript>
                <a href="//disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
                
            </footer>
        </article>
    </div>

</div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [['$','$'], ['\\(','\\)']]
        }
    });
</script>
<script>
    function downloadJSAtOnload(){var n=document.createElement("script");n.src="/scripts/app.min.js",document.body.appendChild(n);if(document.querySelector("math")){var m=document.createElement("script");m.src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML",document.body.appendChild(m)}}window.addEventListener?window.addEventListener("load",downloadJSAtOnload,!1):window.attachEvent?window.attachEvent("onload",downloadJSAtOnload):window.onload=downloadJSAtOnload;
</script>
</body>
</html>
